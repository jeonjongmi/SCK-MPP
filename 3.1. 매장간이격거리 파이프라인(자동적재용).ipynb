{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19dc81a9-f2cd-48ba-ba25-fdb8c3aa2d89",
   "metadata": {},
   "source": [
    "- 20230126 : 원천데이터 로드 로직 수정 -> opn_date <= yyyymmdd < cls_date\n",
    "- 자동적재용 날짜 확인 후 적재"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d4a2e4-db84-496f-9550-2502e5435f5b",
   "metadata": {},
   "source": [
    "# 라이브러리 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "57822d49-8b11-4a32-9263-84f9c026488c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.cloud.aiplatform as aip\n",
    "\n",
    "from typing import NamedTuple\n",
    "\n",
    "import kfp\n",
    "from kfp.v2 import dsl, compiler\n",
    "from kfp.v2.dsl import Artifact, Input, component, Output, Dataset, Metrics\n",
    "\n",
    "from google_cloud_pipeline_components.v1.vertex_notification_email import VertexNotificationEmailOp\n",
    "\n",
    "from jedi import settings\n",
    "settings.case_insensitive_completion = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f3687d-3b8f-41e1-98ee-3593f5a395a5",
   "metadata": {},
   "source": [
    "# 파이프라인 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "982c52e0-18a1-40f6-b04b-2f06ffbd1e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = \"mpp-biz-prd\"\n",
    "REGION = \"asia-northeast3\"\n",
    "BUCKET_URI = f\"gs://gcs-mpp-prd\"\n",
    "PIPELINE_ROOT = \"{}/analytics-pipeline/3.Cannibalization\".format(BUCKET_URI)\n",
    "API_ENDPOINT = \"{}-aiplatform.googleapis.com\".format(REGION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ecc4e044-77c0-48f3-b625-d76db2c4812d",
   "metadata": {},
   "outputs": [],
   "source": [
    "aip.init(project=PROJECT_ID, location=REGION, staging_bucket=BUCKET_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7d0b3ec8-a046-48fe-9c0e-6e252202b051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !gsutil ls -al $BUCKET_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82164146-f466-4ba6-9174-2059cd9e5c5f",
   "metadata": {},
   "source": [
    "# 컴포넌트 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ee0610-540f-47f4-83c2-12a93f67d7d9",
   "metadata": {},
   "source": [
    "- 매장간 이격거리함수 (자동적재)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "324d214a-dbcc-427d-884e-616b99b5d464",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    packages_to_install=['google-cloud-bigquery', 'google-cloud-storage', 'google-oauth2-tool', 'pandas==1.3.5', 'numpy==1.21.6', 'db-dtypes', 'fsspec', 'gcsfs'\n",
    "                        ,'haversine==2.7.0'], \n",
    "    base_image='python:3.7.13',\n",
    "    output_component_file='get_near_stor_distance.yaml'\n",
    ")\n",
    "def read_and_preprocess():\n",
    "    \n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import json\n",
    "    from datetime import datetime\n",
    "    from haversine import haversine\n",
    "    from google.cloud import bigquery\n",
    "    from google.cloud import storage\n",
    "    from google.oauth2 import service_account\n",
    "    from datetime import date, timedelta, datetime\n",
    "    from pytz import timezone\n",
    "\n",
    "    '''\n",
    "        - 빅쿼리로부터 원천 테이블 읽어오는 함수\n",
    "    '''\n",
    "    def get_near_stor_distance(load_day) -> pd.DataFrame():\n",
    "\n",
    "        # gcs bucket으로부터 key.json 불러오기\n",
    "        storage_client = storage.Client()\n",
    "        bucket = storage_client.get_bucket('gcs-mpp-prd')\n",
    "        blob = bucket.blob('analytics-pipeline/1.deficit_prediction/mpp-biz-prd-3758b372e68f.json')\n",
    "\n",
    "        gcs_json_dict = json.loads(blob.download_as_string(client=None))\n",
    "\n",
    "        # Credentials 객체 생성\n",
    "        credentials = service_account.Credentials.from_service_account_info(gcs_json_dict)\n",
    "\n",
    "        # GCP 클라이언트 객체 생성\n",
    "        client = bigquery.Client(credentials=credentials, project=credentials.project_id)\n",
    "        \n",
    "        df = f\"\"\"\n",
    "        SELECT A.partition_date, A.YYYYMMDD, A.STOR_CD, A.DT_YN, B.LONGITUDE, B.LATITUDE, A.OPN_DATE, A.CLS_DATE, B.ROADNM_ADDR, B.ROADNM_ADDR_DTL,\n",
    "        CASE \n",
    "        WHEN A.ADMDIST_SIDO_NM IN ('서울','경기','대전','대구','부산','울산','광주','인천') THEN '50'\n",
    "        WHEN A.ADMDIST_SIGUNGU_NM IN ('청주시','천안시','전주시','포항시','구미시','창원시','김해시','제주시') THEN '50'\n",
    "        ELSE '250'\n",
    "        END AS GRID\n",
    "        FROM `mpp-biz-prd.SCK_DW.DM_STOR_S` AS A, `mpp-biz-prd.SCK_DW.DM_XO_STOR` AS B\n",
    "        WHERE A.STOR_CD = B.STOR_CD\n",
    "        AND partition_date = '{load_day}'\n",
    "        \"\"\"\n",
    "\n",
    "        df = client.query(df).result()\n",
    "\n",
    "        # 원천 데이터프레임 변환\n",
    "        df1 = df.to_dataframe()\n",
    "        \n",
    "        # 230126 조건 추가\n",
    "        df1 = df1[(df1['YYYYMMDD'] >= df1['OPN_DATE']) & (df1['YYYYMMDD'] < df1['CLS_DATE'])].reset_index(drop=True)\n",
    "        \n",
    "        # 기준 데이터프레임 반환\n",
    "        standard_df = df1[df1.columns.difference(['DT_YN'])]\n",
    "\n",
    "        '''\n",
    "        1km 내 인접 점포 list 추가\n",
    "        '''\n",
    "\n",
    "        df2= df1[['YYYYMMDD','STOR_CD','LONGITUDE','LATITUDE','GRID']]\n",
    "\n",
    "        # 매장별 거리구하는 코드\n",
    "        imsi_stor_cd=[] ; imsi_stor_cd_2=[] ; imsi_distance=[]\n",
    "        for idx in df2.itertuples():\n",
    "            start = (float(idx.LATITUDE), float(idx.LONGITUDE) ) # (lat, lon)\n",
    "\n",
    "            for imsi in df2.itertuples():\n",
    "                goal = (float(imsi.LATITUDE),float(imsi.LONGITUDE))\n",
    "                imsi_stor_cd.append(idx.STOR_CD)\n",
    "                imsi_stor_cd_2.append(imsi.STOR_CD)\n",
    "                imsi_distance.append(haversine(start, goal,unit='m'))\n",
    "\n",
    "        df3 = pd.DataFrame(data={'STOR_CD' : imsi_stor_cd, 'STOR_CD_2' : imsi_stor_cd_2, 'DISTANCE' : imsi_distance})\n",
    "        df4 = pd.merge(df3,df1[['STOR_CD','GRID']],how='left', on='STOR_CD')\n",
    "        df5 = df4.loc[((df4.DISTANCE<=1000) & (df4.DISTANCE!=0)) | ((df4.STOR_CD != df4.STOR_CD_2) & (df4.DISTANCE==0))]\n",
    "        df6 = df5.sort_values(by=['STOR_CD', 'DISTANCE']).reset_index(drop=True)\n",
    "\n",
    "        # 그리드50기준\n",
    "        df7 = df6[df6['GRID']=='50']\n",
    "        near_stor_list_500 = [] ; near_stor_list_1000 = []\n",
    "        for idx in df7.itertuples():\n",
    "\n",
    "            # 인접 점포\n",
    "            single_near_stor_list = df7[(df7['STOR_CD'] == idx.STOR_CD) & (df7['DISTANCE'] <= 500) ]['STOR_CD_2'].to_list()\n",
    "            single_near_stor_list =\",\".join(single_near_stor_list)\n",
    "            near_stor_list_500.append(single_near_stor_list)\n",
    "\n",
    "            single_near_stor_list = df7[(df7['STOR_CD'] == idx.STOR_CD) & (df7['DISTANCE'] <= 1000) ]['STOR_CD_2'].to_list()\n",
    "            single_near_stor_list =\",\".join(single_near_stor_list)\n",
    "            near_stor_list_1000.append(single_near_stor_list)\n",
    "\n",
    "        df7 = df7.copy()\n",
    "        df7['NEAR_STOR_2'] = near_stor_list_500\n",
    "        df7['NEAR_STOR_3'] = near_stor_list_1000\n",
    "        df7['NEAR_STOR_GROUP'] = near_stor_list_500\n",
    "\n",
    "\n",
    "        # 그리드250기준\n",
    "        df8 = df6[df6['GRID']=='250']\n",
    "        near_stor_list_500 = [] ; near_stor_list_1000 = []\n",
    "        for idx in df8.itertuples():\n",
    "\n",
    "            # 인접 점포\n",
    "            single_near_stor_list = df8[(df8['STOR_CD'] == idx.STOR_CD) & (df8['DISTANCE'] <= 500)]['STOR_CD_2'].to_list()\n",
    "            single_near_stor_list =\",\".join(single_near_stor_list)\n",
    "            near_stor_list_500.append(single_near_stor_list)\n",
    "\n",
    "            single_near_stor_list_2 = df8[(df8['STOR_CD'] == idx.STOR_CD) & (df8['DISTANCE'] <= 1000)]['STOR_CD_2'].to_list()\n",
    "            single_near_stor_list_2 =\",\".join(single_near_stor_list_2)\n",
    "            near_stor_list_1000.append(single_near_stor_list_2)\n",
    "\n",
    "        df8 = df8.copy()\n",
    "        df8['NEAR_STOR_2'] = near_stor_list_500\n",
    "        df8['NEAR_STOR_3'] = near_stor_list_1000\n",
    "        df8['NEAR_STOR_GROUP'] = near_stor_list_1000\n",
    "\n",
    "        df9 = pd.concat([df7,df8])\n",
    "\n",
    "        '''\n",
    "        5km 내 인접 DT 점포 list 추가\n",
    "        '''\n",
    "\n",
    "        df_2_dt= df1[['STOR_CD','DT_YN','LONGITUDE','LATITUDE']]\n",
    "\n",
    "        # 매장 - DT 매장과의 거리구하는 코드\n",
    "        imsi_stor_cd=[] ; imsi_stor_cd_2=[] ; imsi_distance=[]\n",
    "        for idx in df_2_dt.itertuples():\n",
    "            start = (float(idx.LATITUDE), float(idx.LONGITUDE) ) # (lat, lon)\n",
    "\n",
    "            for imsi in df_2_dt.itertuples():\n",
    "                if df_2_dt['DT_YN'][imsi.Index] == 'Y':\n",
    "                    goal = (float(imsi.LATITUDE),float(imsi.LONGITUDE))\n",
    "                    imsi_stor_cd.append(idx.STOR_CD)\n",
    "                    imsi_stor_cd_2.append(imsi.STOR_CD)\n",
    "                    imsi_distance.append(haversine(start, goal,unit='m'))\n",
    "\n",
    "                else: \n",
    "                    continue\n",
    "\n",
    "        df_3_dt = pd.DataFrame(data={'STOR_CD' : imsi_stor_cd, 'STOR_CD_2' : imsi_stor_cd_2, 'DISTANCE' : imsi_distance})\n",
    "        df_4_dt = df_3_dt.loc[(df_3_dt.DISTANCE<=5000) & (df_3_dt.DISTANCE!=0)]\n",
    "        df_5_dt = df_4_dt.sort_values(by=['STOR_CD', 'DISTANCE']).reset_index(drop=True)\n",
    "\n",
    "        near_stor_list_5000 = []\n",
    "        for idx in df_5_dt.itertuples():\n",
    "\n",
    "            # 인접 점포\n",
    "            single_near_stor_list = df_5_dt[(df_5_dt['STOR_CD'] == idx.STOR_CD) & (df_5_dt['DISTANCE'] <= 5000) ]['STOR_CD_2'].to_list()\n",
    "            single_near_stor_list =\",\".join(single_near_stor_list) # 공백 제거\n",
    "            near_stor_list_5000.append(single_near_stor_list)\n",
    "\n",
    "        df_5_dt = df_5_dt.copy()\n",
    "        df_5_dt['NEAR_STOR_GROUP_DT'] = near_stor_list_5000\n",
    "        df_6_dt = df_5_dt[['STOR_CD', 'NEAR_STOR_GROUP_DT']]\n",
    "\n",
    "        stor_distance_df1 = pd.merge(df9, df_6_dt, how='outer', on='STOR_CD')\n",
    "        final_df = pd.merge(stor_distance_df1, standard_df, how='left', on='STOR_CD')\n",
    "        final_df = final_df.drop_duplicates().reset_index(drop=True) \n",
    "\n",
    "        # 최종 df 생성\n",
    "        final_df.drop('GRID_x', axis=1, inplace=True)\n",
    "        final_df.rename(columns={'GRID_y' : 'GRID', 'STOR_CD_2' : 'NEAR_STOR_1'\n",
    "                            ,'ROADNM_ADDR' : 'STOR_ADDR_1', 'ROADNM_ADDR_DTL' : 'STOR_ADDR_2'}, inplace=True)\n",
    "        final_df = final_df[['YYYYMMDD','STOR_CD','NEAR_STOR_1','LONGITUDE','LATITUDE','OPN_DATE','CLS_DATE','STOR_ADDR_1','STOR_ADDR_2'\n",
    "                         ,'DISTANCE','NEAR_STOR_2','NEAR_STOR_3','NEAR_STOR_GROUP','GRID','NEAR_STOR_GROUP_DT']]\n",
    "\n",
    "        final_df = final_df.astype({'OPN_DATE':'str','CLS_DATE':'str','YYYYMMDD':'str'})\n",
    "        final_df = final_df.replace('',np.nan)\n",
    "        \n",
    "        return final_df\n",
    "\n",
    "    # 적재 날짜 컬럼 생성\n",
    "    viewing_day = datetime.now(timezone('Asia/Seoul'))\n",
    "    viewing_day = datetime(year=viewing_day.year, month=viewing_day.month, day=viewing_day.day).date()\n",
    "    load_day = viewing_day - timedelta(days=1)\n",
    "    \n",
    "    final_df = get_near_stor_distance(load_day)\n",
    "    \n",
    "    \n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.get_bucket('gcs-mpp-prd')\n",
    "    blob = bucket.blob('analytics-pipeline/1.deficit_prediction/mpp-biz-prd-3758b372e68f.json')\n",
    "\n",
    "    gcs_json_dict = json.loads(blob.download_as_string(client=None))\n",
    "\n",
    "    # Credentials 객체 생성\n",
    "    credentials = service_account.Credentials.from_service_account_info(gcs_json_dict)\n",
    "\n",
    "    # GCP 클라이언트 객체 생성\n",
    "    client = bigquery.Client(credentials=credentials, project=credentials.project_id)\n",
    "\n",
    "    # 테이블 append\n",
    "    job = client.load_table_from_dataframe(final_df,'mpp-biz-prd.SCK_MPP.FT_MPP_ANALY_STOR_DISTANCE')\n",
    "    job.result()\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    # final_df.to_csv(final_retention_dataset.path + '.csv', encoding = 'utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5063132-f375-4baf-96c6-8ffe0da38dcf",
   "metadata": {},
   "source": [
    "# 파이프라인 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "22ac6a57-897b-4bd4-a5cb-fd30bf5bd65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(\n",
    "    name='stor-distance-pipeline',\n",
    "    description='Get near store and distance',\n",
    "    pipeline_root=PIPELINE_ROOT\n",
    ")\n",
    "def make_pipeline():\n",
    "    \n",
    "    from google.cloud import storage\n",
    "    from google.oauth2 import service_account\n",
    "    \n",
    "    import json\n",
    "\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.get_bucket('gcs-mpp-prd')\n",
    "    blob = bucket.blob('analytics-pipeline/recipients.json')\n",
    "\n",
    "    RECIPIENTS_LIST = json.loads(blob.download_as_string(client=None))\n",
    "    notify_email_task = VertexNotificationEmailOp(recipients=RECIPIENTS_LIST)\n",
    "\n",
    "    with dsl.ExitHandler(notify_email_task):\n",
    "    \n",
    "        # 1. 빅쿼리 데이터 로드 및 전처리 수행\n",
    "        final_df = read_and_preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f1eab943-6068-4601-bb73-eb33e4bd1af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "compiler.Compiler().compile(\n",
    "    pipeline_func=make_pipeline,\n",
    "    package_path=\"get_near_stor_distance.json\".replace(\" \", \"_\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7c01ec84-18ed-4847-8089-eaf79fd985b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파이프라인 에러 확인시만 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0493e004-660d-4dbb-918e-f95d90bdef9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/397824194879/locations/asia-northeast3/pipelineJobs/stor-distance-pipeline-20230127021259\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/397824194879/locations/asia-northeast3/pipelineJobs/stor-distance-pipeline-20230127021259')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/asia-northeast3/pipelines/runs/stor-distance-pipeline-20230127021259?project=397824194879\n"
     ]
    }
   ],
   "source": [
    "# job = aip.PipelineJob(\n",
    "#     display_name='get_near_stor_distance',\n",
    "#     template_path=\"get_near_stor_distance.json\".replace(\" \", \"_\"),\n",
    "#     pipeline_root=PIPELINE_ROOT,\n",
    "#     location=REGION,\n",
    "#     enable_caching=False\n",
    "# )\n",
    "\n",
    "# job.submit(service_account='mpp-nt-danny-prd@mpp-biz-prd.iam.gserviceaccount.com')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801c630c-6550-4841-8955-a9956a4a5f0d",
   "metadata": {},
   "source": [
    "### Cloud Function 코드\n",
    "- function 만들 때 서비스 계정 danny-prd로 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a497a32-e85c-432f-8c7d-bbbe0c610218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# from google.cloud import aiplatform\n",
    "# PROJECT_ID = 'mpp-biz-prd'         # <---CHANGE THIS\n",
    "# REGION = 'asia-northeast3'                 # <---CHANGE THIS\n",
    "# PIPELINE_ROOT = 'gs://gcs-mpp-prd/analytics-pipeline/3.Cannibalization'   # <---CHANGE THIS\n",
    "\n",
    "# def process_request(request):\n",
    "#   aiplatform.init(\n",
    "#     project=PROJECT_ID,\n",
    "#     location=REGION,\n",
    "#   )\n",
    "\n",
    "#   job = aiplatform.PipelineJob(\n",
    "#     display_name=f'NEAR_STOR_DISTANCE',\n",
    "#     template_path='gs://gcs-mpp-prd/analytics-pipeline/3.Cannibalization/get_near_stor_distance.json',\n",
    "#     pipeline_root=PIPELINE_ROOT,\n",
    "#     location=REGION,\n",
    "#     enable_caching=False\n",
    "#   )\n",
    "\n",
    "#   job.submit(service_account='mpp-nt-danny-prd@mpp-biz-prd.iam.gserviceaccount.com')\n",
    "\n",
    "#   return \"Job submitted\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eea8697-1392-4aec-a06a-e0a7ca76b40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# google-api-python-client>=1.7.8,<2\n",
    "# google-cloud-aiplatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e93e97-f778-42f6-9dc2-8b073d99a772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from kfp.v2.google.client import AIPlatformClient\n",
    "\n",
    "# api_client = AIPlatformClient(\n",
    "#                 project_id=PROJECT_ID,\n",
    "#                 region=REGION,\n",
    "#                 )\n",
    "\n",
    "# SERVICE_ACCOUNT = (\n",
    "#     \"mpp-nt-danny-dev@mpp-biz-dev.iam.dkslrgserviceaccount.com\") # Replace the Xs with your generated service-account.\n",
    "# response = api_client.create_schedule_from_job_spec(\n",
    "#     enable_caching=False,\n",
    "#     job_spec_path=\"month_retention_pipeline.json\",\n",
    "#     #schedule=\"0 1 * * 1-7\", \n",
    "#     schedule = \"0 0 1 * *\",\n",
    "#     time_zone=\"Asia/Seoul\",  # change this as necessary\n",
    "#     # parameter_values={\"display_name\": 'month_retention_pipeline'},\n",
    "#     pipeline_root=PIPELINE_ROOT,  \n",
    "#     service_account=SERVICE_ACCOUNT    \n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994d29e8-56b5-4fec-84a2-5c0c336ab09f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "sckproject",
   "name": "common-cpu.m102",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m102"
  },
  "kernelspec": {
   "display_name": "SCKproject",
   "language": "python",
   "name": "sckproject"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
